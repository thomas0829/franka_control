{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCwbkVFxU5a9"
      },
      "source": [
        "# Envlogger and TFDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VIQjTg467e41"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# python=3.10.12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV4QCcHs_7aW",
        "outputId": "2966c6c2-edbb-4511-e58f-aa8a7b4470bc"
      },
      "outputs": [],
      "source": [
        "#@title Install Pip packages\n",
        "# !pip install tensorflow[and-cuda]==2.15.0\n",
        "# !pip install rlds[tensorflow]\n",
        "# !pip install envlogger[tfds]\n",
        "# !apt-get install libgmp-dev\n",
        "# !pip install numpy\n",
        "# !pip install dm-env\n",
        "# !pip install tqdm\n",
        "# !pip install joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install tensorflow[and-cuda]==2.13.1\n",
        "# pip install rlds[tensorflow]\n",
        "# pip install envlogger[tfds]\n",
        "# sudo apt-get install libgmp-dev\n",
        "# pip install numpy\n",
        "# pip install dm-env\n",
        "# pip install tqdm\n",
        "# pip install joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "y8fkB77rhV4d"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "import os\n",
        "import rlds\n",
        "import envlogger\n",
        "from envlogger.backends import rlds_utils\n",
        "from envlogger.backends import tfds_backend_writer\n",
        "from envlogger.testing import catch_env\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import time\n",
        "from typing import Optional, List"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjilhMvUz5ex"
      },
      "source": [
        "# Generate a dataset\n",
        "\n",
        "In this example, we use the local TFDS backend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lGOghvW3fL1k"
      },
      "outputs": [],
      "source": [
        "#@title load custom data\n",
        "\n",
        "from tqdm import tqdm\n",
        "import joblib\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "load_dir = \"../data/teleop\"\n",
        "exp = \"pick_red\"\n",
        "version = \"0.0.1\" # debug 0.0.1 full 0.0.2\n",
        "load_data_dir = os.path.join(load_dir, exp)\n",
        "filenames = [f for f in listdir(load_data_dir) if isfile(join(load_data_dir, f)) and f.split('_')[0] == \"traj\" and f.split('.')[-1] == \"gz\"]\n",
        "\n",
        "# maximum number of episodes to include per file (episodes will be stored in multiple files and then read as a single dataset).\n",
        "max_episodes_per_shard = 1000\n",
        "save_dir = \"../data/rlds\"\n",
        "generate_data_dir = os.path.join(save_dir, exp, version)\n",
        "os.makedirs(generate_data_dir, exist_ok=True)\n",
        "\n",
        "num_episodes = len(filenames)\n",
        "obs_keys = ['lowdim_ee', 'lowdim_qpos', '207322251049_rgb']\n",
        "key = obs_keys[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "IkanqYVzffME"
      },
      "outputs": [],
      "source": [
        "#@title create pass through env\n",
        "\n",
        "import dm_env\n",
        "from dm_env import specs, TimeStep, StepType\n",
        "\n",
        "class DataGym(dm_env.Environment):\n",
        "\n",
        "  def __init__(self, obs):\n",
        "    self.img = obs[\"207322251049_rgb\"]\n",
        "    self.joint_state = obs[\"lowdim_qpos\"]\n",
        "    self.state = obs[\"lowdim_ee\"]\n",
        "    \n",
        "    self.timestep = 0\n",
        "\n",
        "  def get_obs(self, timestep):\n",
        "    obs_dict = {\n",
        "      \"image\": self.img[self.timestep].astype(self.observation_spec()[\"image\"].dtype),\n",
        "      \"joint_state\": self.joint_state[self.timestep].astype(self.observation_spec()[\"joint_state\"].dtype),\n",
        "      \"state\": self.state[self.timestep].astype(self.observation_spec()[\"state\"].dtype)\n",
        "    }\n",
        "    return obs_dict\n",
        "  \n",
        "  def reset(self):\n",
        "    self.timestep = 0\n",
        "\n",
        "    reward = 0.\n",
        "    discount = 0.\n",
        "    step_type = StepType.FIRST\n",
        "\n",
        "    return TimeStep(step_type, reward, discount, self.get_obs(self.timestep))\n",
        "\n",
        "  def step(self, act):\n",
        "    self.timestep += 1\n",
        "\n",
        "    reward = 0.\n",
        "    discount = 0.\n",
        "    step_type = StepType.MID if self.timestep < len(self.img)-1 else StepType.LAST\n",
        "\n",
        "    return TimeStep(step_type, reward, discount, self.get_obs(self.timestep))\n",
        "\n",
        "  def observation_spec(self):\n",
        "    \"\"\"Returns the observation spec.\"\"\"\n",
        "    return {\n",
        "      \"image\": specs.BoundedArray(shape=self.img[0].shape, dtype=np.uint8, name=\"image\", minimum=0, maximum=255),\n",
        "      \"joint_state\": specs.BoundedArray(shape=self.joint_state[0].shape, dtype=np.float32, name=\"joint_state\", minimum=-1., maximum=1.),\n",
        "      \"state\": specs.BoundedArray(shape=self.state[0].shape, dtype=np.float32, name=\"state\", minimum=-1., maximum=1.),\n",
        "    }\n",
        "  \n",
        "  def action_spec(self):\n",
        "    \"\"\"Returns the action spec.\"\"\"\n",
        "    return specs.BoundedArray(\n",
        "        shape=(7,), dtype=np.float32, name=\"action\", minimum=-1., maximum=1.)\n",
        "    # return {\n",
        "    #   \"world_vector\": specs.BoundedArray(shape=(3,), dtype=np.float32, name=\"world_vector\", minimum=-1., maximum=1.),\n",
        "    #   \"rotation_delta\": specs.BoundedArray(shape=(3,), dtype=np.float32, name=\"rotation_delta\", minimum=-1., maximum=1.),\n",
        "    #   \"open_gripper\": specs.BoundedArray(shape=(1,), dtype=np.float32, name=\"open_gripper\", minimum=-1., maximum=1.),\n",
        "    # }\n",
        "  \n",
        "  # def preprocess_action(self, action):\n",
        "  def preprocess_action(self, action, instruction):\n",
        "    action_dict = {\n",
        "      # \"world_vector\": action[:3].astype(self.action_spec()[\"world_vector\"].dtype),\n",
        "      # \"rotation_delta\": action[3:6].astype(self.action_spec()[\"rotation_delta\"].dtype),\n",
        "      # \"open_gripper\": action[6:].astype(self.action_spec()[\"open_gripper\"].dtype),\n",
        "      \"action\": action.astype(self.action_spec().dtype),\n",
        "      \"natural_language_instruction\": np.array(instruction.encode('utf-8'), dtype=np.object_)\n",
        "    }\n",
        "    return action_dict\n",
        "  \n",
        "e = 0\n",
        "obs, act = joblib.load(os.path.join(load_data_dir, filenames[e]))\n",
        "env = DataGym(obs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [07:59<00:00,  6.06s/it]\n"
          ]
        }
      ],
      "source": [
        "#@title convert custom data to rlds\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "def step_fn(unused_timestep, unused_action, unused_env):\n",
        "  return {'timestamp_ns': time.time_ns()}\n",
        "\n",
        "ds_config = tfds.rlds.rlds_base.DatasetConfig(\n",
        "      name=exp,\n",
        "      observation_info=tfds.features.FeaturesDict({\n",
        "         \"image\": tfds.features.Image(\n",
        "          shape=env.observation_spec()[\"image\"].shape,\n",
        "          dtype=env.observation_spec()[\"image\"].dtype),\n",
        "          \"joint_state\": tfds.features.Tensor(\n",
        "          shape=env.observation_spec()[\"joint_state\"].shape,\n",
        "          dtype=env.observation_spec()[\"joint_state\"].dtype,),\n",
        "          \"state\": tfds.features.Tensor(\n",
        "          shape=env.observation_spec()[\"state\"].shape,\n",
        "          dtype=env.observation_spec()[\"state\"].dtype,),\n",
        "      }),\n",
        "      action_info=\n",
        "      # tfds.features.FeaturesDict({\n",
        "        #  \"world_vector\": tfds.features.Tensor(\n",
        "        #   shape=env.action_spec()[\"world_vector\"].shape,\n",
        "        #   dtype=env.action_spec()[\"world_vector\"].dtype),\n",
        "        #   \"rotation_delta\": tfds.features.Tensor(\n",
        "        #   shape=env.action_spec()[\"rotation_delta\"].shape,\n",
        "        #   dtype=env.action_spec()[\"rotation_delta\"].dtype),\n",
        "        #   \"open_gripper\": tfds.features.Tensor(\n",
        "        #   shape=env.action_spec()[\"open_gripper\"].shape,\n",
        "        #   dtype=env.action_spec()[\"open_gripper\"].dtype,),\n",
        "        # })\n",
        "          tfds.features.Tensor(\n",
        "          shape=env.action_spec().shape,\n",
        "          dtype=env.action_spec().dtype,),\n",
        "          # \"natural_language_instruction\": tfds.features.Tensor(\n",
        "          # shape=(),\n",
        "          # dtype=tf.string,),\n",
        "      reward_info=tf.float64,\n",
        "      discount_info=tf.float64,\n",
        "      step_metadata_info={'timestamp_ns': tf.int64})\n",
        "\n",
        "with envlogger.EnvLogger(\n",
        "        env,\n",
        "        backend = tfds_backend_writer.TFDSBackendWriter(\n",
        "          data_directory=generate_data_dir,\n",
        "          split_name='train',\n",
        "          max_episodes_per_file=max_episodes_per_shard,\n",
        "          ds_config=ds_config),\n",
        "        step_fn=step_fn) as env:\n",
        "  \n",
        "  for e in trange(num_episodes):\n",
        "\n",
        "      obs, act = joblib.load(os.path.join(load_data_dir, filenames[e]))\n",
        "      data_env = DataGym(obs)\n",
        "\n",
        "      env._environment = data_env\n",
        "      timestep = env.reset()\n",
        "\n",
        "      for i in range(act.shape[0]-1):\n",
        "      # while not timestep.last():\n",
        "      # while not timestep.last():\n",
        "\n",
        "        # instruction = \"pick up the red block\"\n",
        "        # action = env.preprocess_action(act[e], instruction)\n",
        "        # action.pop(\"natural_language_instruction\")\n",
        "\n",
        "        action = act[i].astype(np.float32)\n",
        "        timestep = env.step(action)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    'action': Tensor(shape=(7,), dtype=float32),\n",
              "    'discount': float64,\n",
              "    'is_first': bool,\n",
              "    'is_last': bool,\n",
              "    'is_terminal': bool,\n",
              "    'observation': FeaturesDict({\n",
              "        'image': Image(shape=(480, 640, 3), dtype=uint8),\n",
              "        'joint_state': Tensor(shape=(8,), dtype=float32),\n",
              "        'state': Tensor(shape=(7,), dtype=float32),\n",
              "    }),\n",
              "    'reward': float64,\n",
              "    'timestamp_ns': int64,\n",
              "})"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b = tfds.builder_from_directory(builder_dir=generate_data_dir)\n",
        "b.info.features[\"steps\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RkYWg1A_8jX"
      },
      "source": [
        "# Recover a dataset\n",
        "\n",
        "When the process of generating one dataset didn't finish properly, it is possible for the last shard to be incomplete. Envlogger provides the functionality to recover this last shard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSdPMF8V_8LP"
      },
      "outputs": [],
      "source": [
        "recover_dataset_path = generate_data_dir\n",
        "\n",
        "builder = tfds.builder_from_directory(recover_dataset_path)\n",
        "builder = rlds_utils.maybe_recover_last_shard(builder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh63bHYz_mPO"
      },
      "source": [
        "# Load one dataset\n",
        "\n",
        "Loading one dataset generated with the TFDS backend uses just regular TFDS functionality.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYbA7kX_EgSH",
        "outputId": "27e9bb77-8db0-488b-a90f-59eec7d81418"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'steps': <_VariantDataset element_spec={'action': {'open_gripper': TensorSpec(shape=(1,), dtype=tf.float32, name=None), 'rotation_delta': TensorSpec(shape=(3,), dtype=tf.float32, name=None), 'world_vector': TensorSpec(shape=(3,), dtype=tf.float32, name=None)}, 'discount': TensorSpec(shape=(), dtype=tf.float64, name=None), 'is_first': TensorSpec(shape=(), dtype=tf.bool, name=None), 'is_last': TensorSpec(shape=(), dtype=tf.bool, name=None), 'is_terminal': TensorSpec(shape=(), dtype=tf.bool, name=None), 'observation': {'image': TensorSpec(shape=(480, 640, 3), dtype=tf.uint8, name=None), 'joint_state': TensorSpec(shape=(8,), dtype=tf.float32, name=None), 'state': TensorSpec(shape=(7,), dtype=tf.float32, name=None)}, 'reward': TensorSpec(shape=(), dtype=tf.float64, name=None), 'timestamp_ns': TensorSpec(shape=(), dtype=tf.int64, name=None)}>}\n",
            "{'steps': <_VariantDataset element_spec={'action': {'open_gripper': TensorSpec(shape=(1,), dtype=tf.float32, name=None), 'rotation_delta': TensorSpec(shape=(3,), dtype=tf.float32, name=None), 'world_vector': TensorSpec(shape=(3,), dtype=tf.float32, name=None)}, 'discount': TensorSpec(shape=(), dtype=tf.float64, name=None), 'is_first': TensorSpec(shape=(), dtype=tf.bool, name=None), 'is_last': TensorSpec(shape=(), dtype=tf.bool, name=None), 'is_terminal': TensorSpec(shape=(), dtype=tf.bool, name=None), 'observation': {'image': TensorSpec(shape=(480, 640, 3), dtype=tf.uint8, name=None), 'joint_state': TensorSpec(shape=(8,), dtype=tf.float32, name=None), 'state': TensorSpec(shape=(7,), dtype=tf.float32, name=None)}, 'reward': TensorSpec(shape=(), dtype=tf.float64, name=None), 'timestamp_ns': TensorSpec(shape=(), dtype=tf.int64, name=None)}>}\n",
            "{'steps': <_VariantDataset element_spec={'action': {'open_gripper': TensorSpec(shape=(1,), dtype=tf.float32, name=None), 'rotation_delta': TensorSpec(shape=(3,), dtype=tf.float32, name=None), 'world_vector': TensorSpec(shape=(3,), dtype=tf.float32, name=None)}, 'discount': TensorSpec(shape=(), dtype=tf.float64, name=None), 'is_first': TensorSpec(shape=(), dtype=tf.bool, name=None), 'is_last': TensorSpec(shape=(), dtype=tf.bool, name=None), 'is_terminal': TensorSpec(shape=(), dtype=tf.bool, name=None), 'observation': {'image': TensorSpec(shape=(480, 640, 3), dtype=tf.uint8, name=None), 'joint_state': TensorSpec(shape=(8,), dtype=tf.float32, name=None), 'state': TensorSpec(shape=(7,), dtype=tf.float32, name=None)}, 'reward': TensorSpec(shape=(), dtype=tf.float64, name=None), 'timestamp_ns': TensorSpec(shape=(), dtype=tf.int64, name=None)}>}\n"
          ]
        }
      ],
      "source": [
        "load_dataset_path = generate_data_dir\n",
        "\n",
        "loaded_dataset = tfds.builder_from_directory(load_dataset_path).as_dataset(split='all')\n",
        "\n",
        "for e in loaded_dataset:\n",
        "  print(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_VariantDataset element_spec={'action': {'open_gripper': TensorSpec(shape=(1,), dtype=tf.float32, name=None), 'rotation_delta': TensorSpec(shape=(3,), dtype=tf.float32, name=None), 'world_vector': TensorSpec(shape=(3,), dtype=tf.float32, name=None)}, 'discount': TensorSpec(shape=(), dtype=tf.float64, name=None), 'is_first': TensorSpec(shape=(), dtype=tf.bool, name=None), 'is_last': TensorSpec(shape=(), dtype=tf.bool, name=None), 'is_terminal': TensorSpec(shape=(), dtype=tf.bool, name=None), 'observation': {'image': TensorSpec(shape=(480, 640, 3), dtype=tf.uint8, name=None), 'joint_state': TensorSpec(shape=(8,), dtype=tf.float32, name=None), 'state': TensorSpec(shape=(7,), dtype=tf.float32, name=None)}, 'reward': TensorSpec(shape=(), dtype=tf.float64, name=None), 'timestamp_ns': TensorSpec(shape=(), dtype=tf.int64, name=None)}>"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "e[\"steps\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
