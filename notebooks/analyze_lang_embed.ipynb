{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# tokenizer to use\n",
    "# TOKENIZER = \"microsoft/Multilingual-MiniLM-L12-H384\"\n",
    "TOKENIZER = \"openai/clip-vit-large-patch14\"\n",
    "# TOKENIZER = \"openai/clip-vit-base-patch32\"\n",
    "\n",
    "# maximum number of words in a language goal\n",
    "LANG_MAX_WORD_LEN = 25\n",
    "\n",
    "# language embedding obs key name\n",
    "LANG_OBS_KEY = \"lang_embed\"\n",
    "\n",
    "# (HACK) enable language-vision multiplication, post spatial softmax layer\n",
    "# LANG_VIS_MULT_ENABLED = True\n",
    "LANG_VIS_MULT_ENABLED = False\n",
    "\n",
    "# these global variables will be populated automatically\n",
    "\n",
    "# whether language conditioning is enabled\n",
    "LANG_COND_ENABLED = False\n",
    "\n",
    "# these global variables will be populated lazily\n",
    "LANG_EMB_MODEL = None\n",
    "TZ = None\n",
    "\n",
    "def init_lang_model():\n",
    "    from transformers import AutoModel, pipeline, AutoTokenizer, CLIPTextModelWithProjection\n",
    "\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\" # needed to suppress warning about potential deadlock\n",
    "    global LANG_EMB_MODEL\n",
    "    global TZ\n",
    "\n",
    "    # CLIP\n",
    "    LANG_EMB_MODEL = CLIPTextModelWithProjection.from_pretrained(\n",
    "        TOKENIZER,\n",
    "        cache_dir=os.path.expanduser(\"~/tmp/clip\")\n",
    "    ).eval()\n",
    "\n",
    "    TZ = AutoTokenizer.from_pretrained(TOKENIZER, TOKENIZERS_PARALLELISM=True)\n",
    "    \n",
    "    # MiniLM\n",
    "    # https://github.com/microsoft/unilm/tree/master/minilm\n",
    "    # LANG_EMB_MODEL = AutoModel.from_pretrained(TOKENIZER, cache_dir=os.path.expanduser(\"~/tmp/minilm\")).eval()\n",
    "\n",
    "    # pip install --no-cache-dir transformers sentencepiece\n",
    "    # TZ = AutoTokenizer.from_pretrained(TOKENIZER, TOKENIZERS_PARALLELISM=True, use_fast=False)\n",
    "\n",
    "\n",
    "def get_lang_emb(lang):\n",
    "    if lang is None:\n",
    "        return None\n",
    "\n",
    "    if TZ is None:\n",
    "        init_lang_model()\n",
    "    \n",
    "    num_words = len(lang.split())\n",
    "    if num_words > LANG_MAX_WORD_LEN:\n",
    "        raise Exception(\"Number of words {} in sentence {} exceeded max length {}\".format(num_words, lang, LANG_MAX_WORD_LEN))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tokens = TZ(\n",
    "            text=lang,                   # the sentence to be encoded\n",
    "            add_special_tokens=True,             # Add [CLS] and [SEP]\n",
    "            max_length=LANG_MAX_WORD_LEN,  # maximum length of a sentence\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,        # Generate the attention mask\n",
    "            return_tensors=\"pt\",               # ask the function to return PyTorch tensors\n",
    "        )\n",
    "        # lang_emb = LANG_EMB_MODEL(**tokens)[\"pooler_output\"].detach()[0]\n",
    "        lang_emb = LANG_EMB_MODEL(**tokens)['text_embeds'].detach()[0]\n",
    "        lang_emb = lang_emb.cpu().numpy()\n",
    "\n",
    "    return lang_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d4fca6d33d46f89370d852fec3ebab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c5e8635a564ab392894bb603ef578f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c709dacb26ea452aa549b6374fe82bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weirdlab/miniforge3/envs/asid/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6359fa438624d4fb41e4cc1ac1a8cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc43a1d5fa34bfa8ea6a495afb92b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/862k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43aa314d0dca41ad88c4b7a29c7ff9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba7c09999c04305951749da56126d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dada998384e749118a5ad66ba74d0416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.1161942\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "red_embed = get_lang_emb(\"red\")\n",
    "green_embed = get_lang_emb(\"green\")\n",
    "print(np.linalg.norm(red_embed - green_embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.65883\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "red_embed = get_lang_emb(\"pick up the red cube\")\n",
    "green_embed = get_lang_emb(\"pick up the green cube\")\n",
    "print(np.linalg.norm(red_embed - green_embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224.97511\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.dot(red_embed, green_embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246.56877"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(red_embed - green_embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
