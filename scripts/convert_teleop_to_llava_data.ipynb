{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79 data files\n"
     ]
    }
   ],
   "source": [
    "task = \"pick_red\"\n",
    "\n",
    "load_dir = f\"../data/teleop\"\n",
    "data_path_list = glob(os.path.join(load_dir, task, \"*.gz\"), recursive=True)\n",
    "print(\"Found {} data files\".format(len(data_path_list)))\n",
    "\n",
    "save_dir = f\"../data/llava\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lowdim_ee', 'lowdim_qpos', '207322251049_rgb', '207322251049_depth'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = joblib.load(data_path_list[0])\n",
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55, 480, 640, 3), (55, 7))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][\"207322251049_rgb\"].shape, data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[-0.0266508311209918, 0.016585686950799317],\n",
       " [-0.010962512964752837, 0.020432407985895924],\n",
       " [-0.03641561409442955, 0.04720275719556884],\n",
       " [-0.024069496178814466, 0.028907196681839362],\n",
       " [-0.05346590574651613, 0.010457678666933945],\n",
       " [-0.03035266875860437, 0.048358356813292515],\n",
       " [-0.004282234822177378, 1.0]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_values_list = []\n",
    "\n",
    "# load data\n",
    "for data_path in tqdm(data_path_list[:3]):\n",
    "    data = joblib.load(data_path)\n",
    "    for action in data[1]:\n",
    "        action_values_list.append(action)\n",
    "\n",
    "# get min max from action_values_list for each dimension\n",
    "action_values_list = np.stack(action_values_list, axis=0)\n",
    "action_values_list = np.array(action_values_list)\n",
    "min_max_list = []\n",
    "for i in range(action_values_list.shape[1]):\n",
    "    min_max_list.append([np.min(action_values_list[:,i]), np.max(action_values_list[:,i])])\n",
    "min_max_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1.0, 1.0],\n",
       " [-1.0, 1.0],\n",
       " [-1.0, 1.0],\n",
       " [-1.0, 1.0],\n",
       " [-1.0, 1.0],\n",
       " [-1.0, 1.0],\n",
       " [-1.0, 1.0]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_list = [[-1.0, 1.0]]*7\n",
    "min_max_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_to_bins(data, min_value, max_value, num_bins=256):\n",
    "    # Calculate the bin size\n",
    "    bin_size = (max_value - min_value) / num_bins\n",
    "    # Assign each data point to a bin\n",
    "    binned_data = np.floor((data - min_value) / bin_size).astype(int)\n",
    "    # Clip the values to handle the maximum value\n",
    "    binned_data = np.clip(binned_data, 0, num_bins - 1)\n",
    "    return binned_data\n",
    "\n",
    "def discretize(action_values, min_max_lst):\n",
    "    new_action_values = []\n",
    "    for i in range(len(action_values)):\n",
    "        new_action_values.append(discretize_to_bins(action_values[i], min_value = min_max_lst[i][0], max_value = min_max_lst[i][1]))\n",
    "    return new_action_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:27<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished making the dataset ready for llava training! It contains 4355 entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "instruction = \"pick up the red cube\"\n",
    "\n",
    "tot_agentview_entries = []\n",
    "# load data\n",
    "for data_path in tqdm(data_path_list):\n",
    "    data = joblib.load(data_path)\n",
    "\n",
    "    agentview_entries = []\n",
    "    max_step = len(data[0][\"lowdim_ee\"])\n",
    "    for step in range(max_step):\n",
    "        episode = data_path.split(\"/\")[-1].split(\".\")[0]\n",
    "        \n",
    "        # uncomment if you want to save images as jpg\n",
    "        for data_type in [\"rgb\"]: # [\"depth\"]\n",
    "            id_ = \"{}/episode_{}/{}/step_{}.jpg\".format(task, episode, data_type, step)\n",
    "            agentview_img = data[0][f\"207322251049_{data_type}\"][step]\n",
    "\n",
    "            # if data_type == \"depth\":\n",
    "            #     agentview_img = np.repeat(agentview_img[...,None], 3, axis=-1) / 1000.0\n",
    "            #     agentview_img = agentview_img.astype(np.uint8)\n",
    "\n",
    "            agentview_image_path = os.path.join(save_dir, task, id_)\n",
    "            if not os.path.exists(os.path.dirname(agentview_image_path)):\n",
    "                os.makedirs(os.path.dirname(agentview_image_path))\n",
    "            Image.fromarray(agentview_img).save(agentview_image_path)\n",
    "\n",
    "        terminate = 0 if step < max_step - 1 else 1\n",
    "\n",
    "        # action_values = np.concatenate((delta_pos, delta_rot))\n",
    "        action_values = data[1][step]\n",
    "        av = discretize(action_values, min_max_list)\n",
    "        action_text = f\"{terminate} {av[0]} {av[1]} {av[2]} {av[3]} {av[4]} {av[5]} {av[6]}\"\n",
    "\n",
    "        agentview_entry = {\n",
    "            \"id\": id_,\n",
    "            \"image\": agentview_image_path,\n",
    "            \"conversations\": [\n",
    "            {\n",
    "                \"from\": \"human\",\n",
    "                \"value\": f\"What action should the robot take to `{instruction}`\"\n",
    "            },\n",
    "            {\n",
    "                \"from\": \"gpt\",\n",
    "                \"value\": action_text,\n",
    "                \"raw_actions\": action_values.tolist()\n",
    "            },\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        agentview_entries.append(agentview_entry)\n",
    "        tot_agentview_entries.append(agentview_entry)\n",
    "\n",
    "with open('{}/llava_agentview_{}_{}.json'.format(os.path.join(save_dir, task), data_type, task), 'w') as file:\n",
    "    json.dump(agentview_entries, file)\n",
    "with open('{}/llava_agentview_tot.json'.format(os.path.join(save_dir, task)), 'w') as file:\n",
    "    json.dump(tot_agentview_entries, file)\n",
    "print(f'finished making the dataset ready for llava training! It contains {len(tot_agentview_entries)} entries')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mimicgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
